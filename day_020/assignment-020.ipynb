{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QUESTION 1: Read this url and find the 10 most frequent words. romeo_and_juliet = 'http://www.gutenberg.org/files/1112/1112.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ten Most Frequent Words:\n",
      "849: the\n",
      "761: and\n",
      "630: to\n",
      "597: i\n",
      "529: a\n",
      "507: of\n",
      "376: in\n",
      "374: my\n",
      "363: you\n",
      "362: is\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "def get_text_from_url(url):\n",
    "    # Fetch the content of the URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    else:\n",
    "        # Print an error message if the request was not successful\n",
    "        print(f\"Failed to fetch content from {url}. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def clean_and_tokenize_text(text):\n",
    "    # Use BeautifulSoup to remove HTML tags\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    clean_text = soup.get_text()\n",
    "\n",
    "    # Remove non-alphabetic characters and convert to lowercase\n",
    "    clean_text = re.sub(r'[^a-zA-Z\\s]', '', clean_text)\n",
    "    clean_text = clean_text.lower()\n",
    "\n",
    "    # Tokenize the text into words\n",
    "    tokens = clean_text.split()\n",
    "\n",
    "    return tokens\n",
    "\n",
    "def find_most_frequent_words(tokens, num_words=10):\n",
    "    # Use Counter to count the occurrences of each word\n",
    "    word_counter = Counter(tokens)\n",
    "\n",
    "    # Get the most common words\n",
    "    most_common_words = word_counter.most_common(num_words)\n",
    "\n",
    "    return most_common_words\n",
    "\n",
    "# Updated URL of Romeo and Juliet text from Project Gutenberg\n",
    "romeo_and_juliet_url = 'http://www.gutenberg.org/cache/epub/1112/pg1112.txt'\n",
    "\n",
    "# Get text from the URL\n",
    "text_from_url = get_text_from_url(romeo_and_juliet_url)\n",
    "\n",
    "if text_from_url:\n",
    "    # Clean and tokenize the text\n",
    "    tokens = clean_and_tokenize_text(text_from_url)\n",
    "\n",
    "    # Find the 10 most frequent words\n",
    "    most_frequent_words = find_most_frequent_words(tokens, num_words=10)\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Ten Most Frequent Words:\")\n",
    "    for word, count in most_frequent_words:\n",
    "        print(f'{count}: {word}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QUESTION 2: Read the cats API and cats_api = 'https://api.thecatapi.com/v1/breeds' and find : 1, the min, max, mean, median, standard deviation of cats' weight in metric units. ii, the min, max, mean, median, standard deviation of cats' lifespan in years. iii, Create a frequency table of country and breed of cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary Statistics for Weight:\n",
      "count    0.0\n",
      "mean     NaN\n",
      "std      NaN\n",
      "min      NaN\n",
      "25%      NaN\n",
      "50%      NaN\n",
      "75%      NaN\n",
      "max      NaN\n",
      "Name: weight.metric, dtype: float64\n",
      "\n",
      "Summary Statistics for Lifespan:\n",
      "count    67.000000\n",
      "mean     12.074627\n",
      "std       1.828341\n",
      "min       8.000000\n",
      "25%      11.000000\n",
      "50%      12.000000\n",
      "75%      12.500000\n",
      "max      18.000000\n",
      "Name: life_span.years, dtype: float64\n",
      "\n",
      "Frequency Table of Country and Breed:\n",
      "name                  Abyssinian  Aegean  American Bobtail  American Curl  \\\n",
      "origin                                                                      \n",
      "Australia                      0       0                 0              0   \n",
      "Burma                          0       0                 0              0   \n",
      "Canada                         0       0                 0              0   \n",
      "China                          0       0                 0              0   \n",
      "Cyprus                         0       0                 0              0   \n",
      "Egypt                          1       0                 0              0   \n",
      "France                         0       0                 0              0   \n",
      "Greece                         0       1                 0              0   \n",
      "Iran (Persia)                  0       0                 0              0   \n",
      "Isle of Man                    0       0                 0              0   \n",
      "Japan                          0       0                 0              0   \n",
      "Norway                         0       0                 0              0   \n",
      "Russia                         0       0                 0              0   \n",
      "Singapore                      0       0                 0              0   \n",
      "Somalia                        0       0                 0              0   \n",
      "Thailand                       0       0                 0              0   \n",
      "Turkey                         0       0                 0              0   \n",
      "United Arab Emirates           0       0                 0              0   \n",
      "United Kingdom                 0       0                 0              0   \n",
      "United States                  0       0                 1              1   \n",
      "\n",
      "name                  American Shorthair  American Wirehair  Arabian Mau  \\\n",
      "origin                                                                     \n",
      "Australia                              0                  0            0   \n",
      "Burma                                  0                  0            0   \n",
      "Canada                                 0                  0            0   \n",
      "China                                  0                  0            0   \n",
      "Cyprus                                 0                  0            0   \n",
      "Egypt                                  0                  0            0   \n",
      "France                                 0                  0            0   \n",
      "Greece                                 0                  0            0   \n",
      "Iran (Persia)                          0                  0            0   \n",
      "Isle of Man                            0                  0            0   \n",
      "Japan                                  0                  0            0   \n",
      "Norway                                 0                  0            0   \n",
      "Russia                                 0                  0            0   \n",
      "Singapore                              0                  0            0   \n",
      "Somalia                                0                  0            0   \n",
      "Thailand                               0                  0            0   \n",
      "Turkey                                 0                  0            0   \n",
      "United Arab Emirates                   0                  0            1   \n",
      "United Kingdom                         0                  0            0   \n",
      "United States                          1                  1            0   \n",
      "\n",
      "name                  Australian Mist  Balinese  Bambino  ...  Siberian  \\\n",
      "origin                                                    ...             \n",
      "Australia                           1         0        0  ...         0   \n",
      "Burma                               0         0        0  ...         0   \n",
      "Canada                              0         0        0  ...         0   \n",
      "China                               0         0        0  ...         0   \n",
      "Cyprus                              0         0        0  ...         0   \n",
      "Egypt                               0         0        0  ...         0   \n",
      "France                              0         0        0  ...         0   \n",
      "Greece                              0         0        0  ...         0   \n",
      "Iran (Persia)                       0         0        0  ...         0   \n",
      "Isle of Man                         0         0        0  ...         0   \n",
      "Japan                               0         0        0  ...         0   \n",
      "Norway                              0         0        0  ...         0   \n",
      "Russia                              0         0        0  ...         1   \n",
      "Singapore                           0         0        0  ...         0   \n",
      "Somalia                             0         0        0  ...         0   \n",
      "Thailand                            0         0        0  ...         0   \n",
      "Turkey                              0         0        0  ...         0   \n",
      "United Arab Emirates                0         0        0  ...         0   \n",
      "United Kingdom                      0         0        0  ...         0   \n",
      "United States                       0         1        1  ...         0   \n",
      "\n",
      "name                  Singapura  Snowshoe  Somali  Sphynx  Tonkinese  Toyger  \\\n",
      "origin                                                                         \n",
      "Australia                     0         0       0       0          0       0   \n",
      "Burma                         0         0       0       0          0       0   \n",
      "Canada                        0         0       0       1          1       0   \n",
      "China                         0         0       0       0          0       0   \n",
      "Cyprus                        0         0       0       0          0       0   \n",
      "Egypt                         0         0       0       0          0       0   \n",
      "France                        0         0       0       0          0       0   \n",
      "Greece                        0         0       0       0          0       0   \n",
      "Iran (Persia)                 0         0       0       0          0       0   \n",
      "Isle of Man                   0         0       0       0          0       0   \n",
      "Japan                         0         0       0       0          0       0   \n",
      "Norway                        0         0       0       0          0       0   \n",
      "Russia                        0         0       0       0          0       0   \n",
      "Singapore                     1         0       0       0          0       0   \n",
      "Somalia                       0         0       1       0          0       0   \n",
      "Thailand                      0         0       0       0          0       0   \n",
      "Turkey                        0         0       0       0          0       0   \n",
      "United Arab Emirates          0         0       0       0          0       0   \n",
      "United Kingdom                0         0       0       0          0       0   \n",
      "United States                 0         1       0       0          0       1   \n",
      "\n",
      "name                  Turkish Angora  Turkish Van  York Chocolate  \n",
      "origin                                                             \n",
      "Australia                          0            0               0  \n",
      "Burma                              0            0               0  \n",
      "Canada                             0            0               0  \n",
      "China                              0            0               0  \n",
      "Cyprus                             0            0               0  \n",
      "Egypt                              0            0               0  \n",
      "France                             0            0               0  \n",
      "Greece                             0            0               0  \n",
      "Iran (Persia)                      0            0               0  \n",
      "Isle of Man                        0            0               0  \n",
      "Japan                              0            0               0  \n",
      "Norway                             0            0               0  \n",
      "Russia                             0            0               0  \n",
      "Singapore                          0            0               0  \n",
      "Somalia                            0            0               0  \n",
      "Thailand                           0            0               0  \n",
      "Turkey                             1            1               0  \n",
      "United Arab Emirates               0            0               0  \n",
      "United Kingdom                     0            0               0  \n",
      "United States                      0            0               1  \n",
      "\n",
      "[20 rows x 67 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Cat API URL\n",
    "cats_api = 'https://api.thecatapi.com/v1/breeds'\n",
    "\n",
    "# Fetch data from the Cat API\n",
    "response = requests.get(cats_api)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse JSON data\n",
    "    cat_data = response.json()\n",
    "\n",
    "    # Create a DataFrame from the JSON data\n",
    "    df = pd.DataFrame(cat_data)\n",
    "\n",
    "    # Convert weight to metric units (assuming the weight is in grams)\n",
    "    df['weight.metric'] = df['weight'].apply(lambda x: x['metric'])\n",
    "\n",
    "    # Extract numerical values for weight and lifespan\n",
    "    df['weight.metric'] = pd.to_numeric(df['weight.metric'], errors='coerce')\n",
    "    df['life_span.years'] = df['life_span'].str.extract('(\\d+)').astype(float)\n",
    "\n",
    "    # Display summary statistics for weight and lifespan\n",
    "    weight_stats = df['weight.metric'].describe()\n",
    "    lifespan_stats = df['life_span.years'].describe()\n",
    "\n",
    "    # Create a frequency table of country and breed\n",
    "    frequency_table = pd.crosstab(df['origin'], df['name'])\n",
    "\n",
    "    print(\"\\nSummary Statistics for Weight:\")\n",
    "    print(weight_stats)\n",
    "\n",
    "    print(\"\\nSummary Statistics for Lifespan:\")\n",
    "    print(lifespan_stats)\n",
    "\n",
    "    print(\"\\nFrequency Table of Country and Breed:\")\n",
    "    print(frequency_table)\n",
    "else:\n",
    "    print(f\"Failed to fetch data from the Cat API. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QUESTION 3: Read the countries API and find i, the 10 largest countries. ii, the 10 most spoken languages. iii, the total number of languages in the countries API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Names: Index(['name', 'tld', 'cca2', 'ccn3', 'cca3', 'independent', 'status',\n",
      "       'unMember', 'currencies', 'idd', 'capital', 'altSpellings', 'region',\n",
      "       'subregion', 'languages', 'translations', 'latlng', 'landlocked',\n",
      "       'area', 'demonyms', 'flag', 'maps', 'population', 'car', 'timezones',\n",
      "       'continents', 'flags', 'coatOfArms', 'startOfWeek', 'capitalInfo',\n",
      "       'postalCode', 'cioc', 'borders', 'fifa', 'gini'],\n",
      "      dtype='object')\n",
      "\n",
      "10 Largest Countries:\n",
      "                                                  name  \\\n",
      "218  {'common': 'Russia', 'official': 'Russian Fede...   \n",
      "120  {'common': 'Antarctica', 'official': 'Antarcti...   \n",
      "237  {'common': 'Canada', 'official': 'Canada', 'na...   \n",
      "84   {'common': 'China', 'official': 'People's Repu...   \n",
      "231  {'common': 'United States', 'official': 'Unite...   \n",
      "68   {'common': 'Brazil', 'official': 'Federative R...   \n",
      "222  {'common': 'Australia', 'official': 'Commonwea...   \n",
      "100  {'common': 'India', 'official': 'Republic of I...   \n",
      "142  {'common': 'Argentina', 'official': 'Argentine...   \n",
      "73   {'common': 'Kazakhstan', 'official': 'Republic...   \n",
      "\n",
      "                           tld cca2 ccn3 cca3 independent  \\\n",
      "218            [.ru, .su, .рф]   RU  643  RUS        True   \n",
      "120                      [.aq]   AQ  010  ATA       False   \n",
      "237                      [.ca]   CA  124  CAN        True   \n",
      "84   [.cn, .中国, .中國, .公司, .网络]   CN  156  CHN        True   \n",
      "231                      [.us]   US  840  USA        True   \n",
      "68                       [.br]   BR  076  BRA        True   \n",
      "222                      [.au]   AU  036  AUS        True   \n",
      "100                      [.in]   IN  356  IND        True   \n",
      "142                      [.ar]   AR  032  ARG        True   \n",
      "73                 [.kz, .қаз]   KZ  398  KAZ        True   \n",
      "\n",
      "                  status  unMember  \\\n",
      "218  officially-assigned      True   \n",
      "120  officially-assigned     False   \n",
      "237  officially-assigned      True   \n",
      "84   officially-assigned      True   \n",
      "231  officially-assigned      True   \n",
      "68   officially-assigned      True   \n",
      "222  officially-assigned      True   \n",
      "100  officially-assigned      True   \n",
      "142  officially-assigned      True   \n",
      "73   officially-assigned      True   \n",
      "\n",
      "                                            currencies  \\\n",
      "218  {'RUB': {'name': 'Russian ruble', 'symbol': '₽'}}   \n",
      "120                                                NaN   \n",
      "237  {'CAD': {'name': 'Canadian dollar', 'symbol': ...   \n",
      "84    {'CNY': {'name': 'Chinese yuan', 'symbol': '¥'}}   \n",
      "231  {'USD': {'name': 'United States dollar', 'symb...   \n",
      "68   {'BRL': {'name': 'Brazilian real', 'symbol': '...   \n",
      "222  {'AUD': {'name': 'Australian dollar', 'symbol'...   \n",
      "100   {'INR': {'name': 'Indian rupee', 'symbol': '₹'}}   \n",
      "142  {'ARS': {'name': 'Argentine peso', 'symbol': '...   \n",
      "73   {'KZT': {'name': 'Kazakhstani tenge', 'symbol'...   \n",
      "\n",
      "                                                   idd  ...       continents  \\\n",
      "218  {'root': '+7', 'suffixes': ['3', '4', '5', '8'...  ...   [Europe, Asia]   \n",
      "120                                                 {}  ...     [Antarctica]   \n",
      "237                   {'root': '+1', 'suffixes': ['']}  ...  [North America]   \n",
      "84                   {'root': '+8', 'suffixes': ['6']}  ...           [Asia]   \n",
      "231  {'root': '+1', 'suffixes': ['201', '202', '203...  ...  [North America]   \n",
      "68                   {'root': '+5', 'suffixes': ['5']}  ...  [South America]   \n",
      "222                  {'root': '+6', 'suffixes': ['1']}  ...        [Oceania]   \n",
      "100                  {'root': '+9', 'suffixes': ['1']}  ...           [Asia]   \n",
      "142                  {'root': '+5', 'suffixes': ['4']}  ...  [South America]   \n",
      "73              {'root': '+7', 'suffixes': ['6', '7']}  ...           [Asia]   \n",
      "\n",
      "                                                 flags  \\\n",
      "218  {'png': 'https://flagcdn.com/w320/ru.png', 'sv...   \n",
      "120  {'png': 'https://flagcdn.com/w320/aq.png', 'sv...   \n",
      "237  {'png': 'https://flagcdn.com/w320/ca.png', 'sv...   \n",
      "84   {'png': 'https://flagcdn.com/w320/cn.png', 'sv...   \n",
      "231  {'png': 'https://flagcdn.com/w320/us.png', 'sv...   \n",
      "68   {'png': 'https://flagcdn.com/w320/br.png', 'sv...   \n",
      "222  {'png': 'https://flagcdn.com/w320/au.png', 'sv...   \n",
      "100  {'png': 'https://flagcdn.com/w320/in.png', 'sv...   \n",
      "142  {'png': 'https://flagcdn.com/w320/ar.png', 'sv...   \n",
      "73   {'png': 'https://flagcdn.com/w320/kz.png', 'sv...   \n",
      "\n",
      "                                            coatOfArms startOfWeek  \\\n",
      "218  {'png': 'https://mainfacts.com/media/images/co...      monday   \n",
      "120  {'png': 'https://mainfacts.com/media/images/co...      monday   \n",
      "237  {'png': 'https://mainfacts.com/media/images/co...      sunday   \n",
      "84   {'png': 'https://mainfacts.com/media/images/co...      monday   \n",
      "231  {'png': 'https://mainfacts.com/media/images/co...      sunday   \n",
      "68   {'png': 'https://mainfacts.com/media/images/co...      monday   \n",
      "222  {'png': 'https://mainfacts.com/media/images/co...      monday   \n",
      "100  {'png': 'https://mainfacts.com/media/images/co...      monday   \n",
      "142  {'png': 'https://mainfacts.com/media/images/co...      monday   \n",
      "73   {'png': 'https://mainfacts.com/media/images/co...      monday   \n",
      "\n",
      "                      capitalInfo  \\\n",
      "218     {'latlng': [55.75, 37.6]}   \n",
      "120                            {}   \n",
      "237    {'latlng': [45.42, -75.7]}   \n",
      "84    {'latlng': [39.92, 116.38]}   \n",
      "231   {'latlng': [38.89, -77.05]}   \n",
      "68   {'latlng': [-15.79, -47.88]}   \n",
      "222  {'latlng': [-35.27, 149.13]}   \n",
      "100      {'latlng': [28.6, 77.2]}   \n",
      "142  {'latlng': [-34.58, -58.67]}   \n",
      "73     {'latlng': [51.16, 71.45]}   \n",
      "\n",
      "                                            postalCode cioc  \\\n",
      "218         {'format': '######', 'regex': '^(\\d{6})$'}  RUS   \n",
      "120                                                NaN  NaN   \n",
      "237  {'format': '@#@ #@#', 'regex': '^([ABCEGHJKLMN...  CAN   \n",
      "84          {'format': '######', 'regex': '^(\\d{6})$'}  CHN   \n",
      "231  {'format': '#####-####', 'regex': '^\\d{5}(-\\d{...  USA   \n",
      "68       {'format': '#####-###', 'regex': '^(\\d{8})$'}  BRA   \n",
      "222           {'format': '####', 'regex': '^(\\d{4})$'}  AUS   \n",
      "100         {'format': '######', 'regex': '^(\\d{6})$'}  IND   \n",
      "142  {'format': '@####@@@', 'regex': '^([A-Z]\\d{4}[...  ARG   \n",
      "73          {'format': '######', 'regex': '^(\\d{6})$'}  KAZ   \n",
      "\n",
      "                                               borders  fifa            gini  \n",
      "218  [AZE, BLR, CHN, EST, FIN, GEO, KAZ, PRK, LVA, ...   RUS  {'2018': 37.5}  \n",
      "120                                                NaN   NaN             NaN  \n",
      "237                                              [USA]   CAN  {'2017': 33.3}  \n",
      "84   [AFG, BTN, MMR, HKG, IND, KAZ, NPL, PRK, KGZ, ...   CHN  {'2016': 38.5}  \n",
      "231                                         [CAN, MEX]   USA  {'2018': 41.4}  \n",
      "68   [ARG, BOL, COL, GUF, GUY, PRY, PER, SUR, URY, ...   BRA  {'2019': 53.4}  \n",
      "222                                                NaN   AUS  {'2014': 34.4}  \n",
      "100                     [BGD, BTN, MMR, CHN, NPL, PAK]   IND  {'2011': 35.7}  \n",
      "142                          [BOL, BRA, CHL, PRY, URY]   ARG  {'2019': 42.9}  \n",
      "73                           [CHN, KGZ, RUS, TKM, UZB]   KAZ  {'2018': 27.8}  \n",
      "\n",
      "[10 rows x 35 columns]\n",
      "\n",
      "10 Most Spoken Languages:\n",
      "languages\n",
      "eng    91\n",
      "fra    46\n",
      "ara    25\n",
      "spa    24\n",
      "por    10\n",
      "rus     7\n",
      "nld     7\n",
      "zho     5\n",
      "deu     5\n",
      "tsn     4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total Number of Languages: 155\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Countries API URL\n",
    "countries_api = 'https://restcountries.com/v3.1/all'\n",
    "\n",
    "# Fetch data from the Countries API\n",
    "response = requests.get(countries_api)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse JSON data\n",
    "    countries_data = response.json()\n",
    "\n",
    "    # Create a DataFrame from the JSON data\n",
    "    countries_df = pd.DataFrame(countries_data)\n",
    "\n",
    "    # Find the 10 largest countries\n",
    "    largest_countries = countries_df.nlargest(10, 'area')\n",
    "\n",
    "    # Find the 10 most spoken languages\n",
    "    languages_count = countries_df['languages'].explode().value_counts()\n",
    "    most_spoken_languages = languages_count.nlargest(10)\n",
    "\n",
    "    # Calculate the total number of languages\n",
    "    total_languages = languages_count.size\n",
    "    \n",
    "    # Print column names\n",
    "    print(\"Column Names:\", largest_countries.columns)\n",
    "    \n",
    "    # Print 10 Largest Countries\n",
    "    print(\"\\n10 Largest Countries:\")\n",
    "    print(largest_countries)\n",
    "    \n",
    "    # Print most spokrn languages\n",
    "    print(\"\\n10 Most Spoken Languages:\")\n",
    "    print(most_spoken_languages)\n",
    "    \n",
    "    # print total number of labguages\n",
    "    print(f\"\\nTotal Number of Languages: {total_languages}\")\n",
    "\n",
    "else:\n",
    "    print(f\"Failed to fetch data from the Countries API. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QUESTION 4: UCI is one of the most common places to get data sets for data science and machine learning. Read the content of UCL (https://archive.ics.uci.edu/ml/datasets.php). Without additional libraries it will be difficult, so you may try it with BeautifulSoup4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch content. Status code: 404\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the UCI Machine Learning Repository\n",
    "uci_url = \"https://archive.ics.uci.edu/ml/datasets.php\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(uci_url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Extract and print the text content of the page\n",
    "    print(soup.get_text())\n",
    "else:\n",
    "    print(f\"Failed to fetch content. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
